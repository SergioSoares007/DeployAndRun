<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | DeployAndRun</title><meta name=keywords content><meta name=description content="Posts - DeployAndRun"><meta name=author content="Sérgio Soares"><link rel=canonical href=http://localhost:1313/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.36819bea596090d8b48cf10d9831382996197aa7e4fc86f792f7c08c9ca4d23b.css integrity="sha256-NoGb6llgkNi0jPENmDE4KZYZeqfk/Ib3kvfAjJyk0js=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/posts/index.xml><link rel=alternate hreflang=en href=http://localhost:1313/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/"><meta property="og:site_name" content="DeployAndRun"><meta property="og:title" content="Posts"><meta property="og:description" content="Tech Blog"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Tech Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Customizing Large Language Models</h2></header><div class=entry-content><p>Techniques for Customizing Large Language Models (LLMs) As large language models (LLMs) continue to evolve, the need for customization becomes increasingly important to tailor their capabilities to specific use cases. This blog post delves into several prominent techniques for LLM customization: prompting (including multi-shot and chaining), utilizing tools, Retrieval-Augmented Generation (RAG), and fine-tuning. Each technique has its own pros and cons, and understanding them will equip developers to make informed decisions in their projects.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;587 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Customizing Large Language Models" href=http://localhost:1313/posts/post7/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Gradio</h2></header><div class=entry-content><p>Getting Started with Gradio: Building Interactive Interfaces for Machine Learning Models In the fast-paced world of machine learning and AI, creating interactive applications that allow users to engage with models is becoming increasingly valuable. Enter Gradio, a Python library designed to make building user interfaces for machine learning models straightforward and efficient. In this blog post, we’ll explore how Gradio works, how to use it, and how to integrate it with popular LLM APIs like OpenAI’s GPT.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;672 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Gradio" href=http://localhost:1313/posts/post4/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>How to Fine-Tune a Closed Source LLM like ChatGPT</h2></header><div class=entry-content><p>How to Fine-Tune a Closed Source LLM like ChatGPT: A Step-by-Step Guide Fine-tuning closed-source large language models (LLMs) such as ChatGPT represents a unique challenge for developers. While the core model can often be accessed via APIs, customizing it to meet specific needs requires a tailored approach. This guide will walk you through the process of fine-tuning a closed-source LLM, including insight into what can be achieved, a step-by-step example, and potential use cases.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;652 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to How to Fine-Tune a Closed Source LLM like ChatGPT" href=http://localhost:1313/posts/post9/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Hugging Face</h2></header><div class=entry-content><p>Understanding Hugging Face: A Comprehensive Guide Hugging Face has become a leading platform in the field of Natural Language Processing (NLP) and machine learning, especially known for its user-friendly tools and extensive community resources. In this blog, we’ll delve into what Hugging Face is, how it works, and the key libraries it offers, including transformers, datasets, accelerate, and hub.
What is Hugging Face? Hugging Face started as a chatbot company but quickly shifted focus to NLP and now is a hub for state-of-the-art machine learning models. The platform is built around the community approach, enabling developers of all levels to collaborate and share pre-trained models, datasets, and innovations in machine learning.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;661 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Hugging Face" href=http://localhost:1313/posts/post5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>JWT</h2></header><div class=entry-content><p>Understanding JSON Web Tokens (JWT) In the realm of modern web applications, ensuring secure and efficient user authentication is crucial. JSON Web Tokens (JWT) have emerged as a popular solution for this purpose. This blog post will break down what JWTs are, how they work, their benefits, and provide a basic implementation along with security best practices.
What are JWTs? JSON Web Tokens (JWT) are an open standard (RFC 7519) for securely transmitting information between parties as a JSON object. They are used for authentication and information exchange in a compact, URL-safe manner. A JWT is essentially a token that can encapsulate user and permission data, which can be verified and trusted.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;721 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to JWT" href=http://localhost:1313/posts/post2/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>NLP, LLMs, LR and ML</h2></header><div class=entry-content><p>Understanding NLP, LLMs, Linear Regression, and the Landscape of Machine Learning Machine Learning (ML) has reshaped modern technology — powering everything from recommendation systems to self-driving cars. Within this field, Natural Language Processing (NLP) and Large Language Models (LLMs) have become particularly prominent due to the rise of generative AI.
In this blog post, we’ll demystify the connections between these areas, explore the role of Linear Regression, and look at how they fit into the broader ML ecosystem.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;584 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to NLP, LLMs, LR and ML" href=http://localhost:1313/posts/post8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>RAG</h2></header><div class=entry-content><p>Understanding Retrieval Augmented Generation (RAG) Retrieval Augmented Generation (RAG) is an innovative machine learning architecture that combines the strengths of information retrieval and text generation. As developers and machine learning practitioners, understanding RAG can elevate the capabilities of your AI models, enabling them to provide more relevant and context-aware responses.
In this blog post, we’ll explore the workings of RAG, the importance of vectors, and how they facilitate efficient operations within this powerful framework.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;773 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to RAG" href=http://localhost:1313/posts/post6/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>This bitter earth</h2></header><div class=entry-content><p>This bitter earth
Well, what the fruit it bears
Ooooh
This bitter earth
And if my life
Is like the dust
Oooh that hides
The glow of a rose
What good am I?
Heaven only knows
Lord, this bitter earth
Yes can be so cold
Today you’re young
Too soon, you’re old
But while a voice
Within me cries
I’m sure someone may answer my call
And this bitter earth, oooh
May not, oh, be so bitter after all
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;122 words&nbsp;·&nbsp;Max Richter</footer><a class=entry-link aria-label="post link to This bitter earth" href=http://localhost:1313/posts/post1/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Understanding the Foundations of Large Language Models (LLMs)</h2></header><div class=entry-content><p>Understanding the Foundations of Large Language Models (LLMs) Meta-Description Dive into the core concepts behind large language models (LLMs) and the Transformer architecture. Learn about tokens, embeddings, weights, the attention mechanism, and how these elements combine to power modern AI applications.
Large language models (LLMs) have revolutionized natural language processing (NLP), making it possible for machines to understand and generate human-like text. At the heart of these models lies the Transformer architecture, which leverages various components to analyze and generate language in a way that mimics human writing. In this blog post, we will explore the fundamental building blocks of LLMs, including tokens, embeddings, weights, attention mechanisms, and important concepts like fine-tuning and inference vs. training.
...</p></div><footer class=entry-footer><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;960 words&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Understanding the Foundations of Large Language Models (LLMs)" href=http://localhost:1313/posts/post3/></a></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><footer class=footer><div class=footer__inner><div class=copyright>© 2025 Sérgio Soares · Built with care and open source</div></div></footer><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>